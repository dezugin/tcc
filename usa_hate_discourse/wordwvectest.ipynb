{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import json\n",
    "\n",
    "# Assume we have a list of sentences. For simplicity, let's use a dummy list.\n",
    "sentences = [\n",
    "    \"This is a sample sentence\",\n",
    "    \"Word2Vec is an interesting algorithm\",\n",
    "    \"Bag of words is a common approach\"\n",
    "]\n",
    "\n",
    "# Tokenize and preprocess the sentences\n",
    "tokenized_sentences = [simple_preprocess(sentence) for sentence in sentences]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Now, let's convert the model's vocabulary and vectors into a JSONL format.\n",
    "with open(\"word2vec.jsonl\", \"w\") as file:\n",
    "    for word in model.wv.index_to_key:\n",
    "        vector = model.wv[word].tolist()  # Convert numpy array to list\n",
    "        data = {\"word\": word, \"vector\": vector}\n",
    "        file.write(json.dumps(data) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
